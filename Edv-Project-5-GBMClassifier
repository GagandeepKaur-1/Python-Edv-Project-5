import numpy as np
import pandas as pd
import os

os.getcwd()

os.chdir("C:\\Users\\Gagandeep\\Documents")

p_train=pd.read_csv("Property_train.csv")
p_test=pd.read_csv("Property_test_share.csv")

p_train.dtypes

cat_to_numeric=['PriceIndex'+str(i) for i in range(1,10)]

for col in cat_to_numeric:
    p_train[col]=pd.to_numeric(p_train[col],errors="coerce")
    p_test[col]=pd.to_numeric(p_train[col],errors="coerce")
    p_train[col]=p_train[col].fillna(p_train[col].median())
    p_test[col]=p_test[col].fillna(p_train[col].median())

p_train.isnull().sum().sum()

p_test.isnull().sum().sum()

p_train["Data"]="Train"
p_test["Data"]="Test"
p_test["Junk"]=np.nan

all_data=pd.concat([p_train,p_test],axis=0)



p_train.dtypes

p_test.dtypes

cat_cols=['InteriorsStyle', 'ListDate', 'Material', 'Agency', 'AreaIncomeType',
       'EnvRating', 'PRIMEUNIT', 'Channel', 'PlotType', 'Architecture',
       'Region', 'SubModel', 'Facade', 'State', 'RegionType','Zip']

for col in cat_cols:
    k=all_data[col].value_counts()
    cats=k[k>=1000].index[:-1]
    
    for cat in cats:
        name=col+'_'+str(cat)
        all_data[name]=(all_data[col]==cat).astype(int)
        
    del all_data[col]       



all_data.shape

train_data=all_data[(all_data["Data"]=="Train")]
train_data=train_data.drop(["Data"],1)

test_data=all_data[(all_data["Data"]=="Test")]
test_data=test_data.drop(["Data"],1)

train_data.shape

test_data.shape



from sklearn.model_selection import train_test_split
train1,train2=train_test_split(train_data,test_size=0.20,random_state=2)

train1y=train1["Junk"]
train1X=train1.drop(["Junk"],1)
train2y=train2["Junk"]
train2X=train2.drop(["Junk"],1)

gbm_params={"n_estimators":[50,100,200,500],"learning_rate":[0.001,0.01,0.5,0.1,0.4,0.8,1],"max_depth":[1,2,3,4,5,6],
            "subsample":[0.5,0.8,1],"max_features":[0.1,0.3,0.5,0.8,1]}

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import RandomizedSearchCV
model=GradientBoostingClassifier()
random_search=RandomizedSearchCV(model,scoring="roc_auc",param_distributions=gbm_params,cv=10,n_iter=10,n_jobs=-1,verbose=False)

random_search.fit(train1X,train1y)



random_search.best_estimator_

gbm=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='deviance', max_depth=6,
                           max_features=0.3, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_impurity_split=None,
                           min_samples_leaf=1, min_samples_split=2,
                           min_weight_fraction_leaf=0.0, n_estimators=500,
                           n_iter_no_change=None, presort='deprecated',
                           random_state=None, subsample=1, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)

gbm.fit(train1X,train1y)

from sklearn.metrics import roc_auc_score
y_pred=gbm.predict(train2X)

a=roc_auc_score(train2y,y_pred)
a



